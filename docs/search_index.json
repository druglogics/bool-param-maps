[
["index.html", "A study in boolean model parameterization Intro", " A study in boolean model parameterization John Zobolas Last updated: 21 September, 2020 Intro Several analyses/investigations relating to the balance logical operators paper. Loading libraries: library(xfun) library(knitr) library(dplyr) library(tidyr) library(tibble) library(corrplot) library(latex2exp) library(ggpubr) library(stringr) library(ggplot2) library(DT) library(usefun) library(emba) library(forcats) library(scales) library(gtools) suppressPackageStartupMessages(library(ComplexHeatmap)) library(glmnet) library(randomForest) library(ranger) library(uwot) library(Ckmeans.1d.dp) "],
["bbr-function-analysis.html", "BBR Function Analysis Balance Boolean Regulatory Functions (BBRs) Truth Density Data Analysis", " BBR Function Analysis Balance Boolean Regulatory Functions (BBRs) The BBRs (Balance Boolean Regulatory functions) functions have **two sets of regulators: activators* (on one side) and inhibitors (on the other). I have observed two main classes of these functions: one that uses logical rules to derive the combinatorial activity of the regulators and one that relies on the combined additive activity (via pseudo-boolean constrains). Let \\(f\\) be a boolean function \\(f(x,y):\\{0,1\\}^n \\rightarrow \\{0,1\\}\\), with \\(m\\) activators \\(x=\\{x_i\\}_{i=1}^{m}\\) and \\(k\\) inhibitors \\(y=\\{y_i\\}_{i=1}^{k}\\), that is a total of \\(n=m+k\\) regulators. The BBRs have a (non-DNF) representation that puts the different category regulators in 2 separate groups and a link boolean operator between them. As such, for a link operator to make sense, we have that \\(m,k \\ge 1\\) (at least one regulator in each category). An example of such a function that has been used in the literature (Mendoza and Xenarios 2006) is the formula with the AND-NOT link operator: AND-NOT: \\[f(x,y) = \\left(\\bigvee_{i=1}^{m} x_i\\right) \\land \\lnot \\left(\\bigvee_{i=1}^{k} y_i\\right)\\] A variant of that one that shifts the balance in favor of the activators (as we will see the truth density significantly increases) is the function with the OR-NOT link operator: OR-NOT: \\[f(x,y) = \\left(\\bigvee_{i=1}^{m} x_i\\right) \\lor \\lnot \\left(\\bigvee_{i=1}^{k} y_i\\right)\\] Another one of this type of functions is the next one: BalanceOp1: \\[f(x,y) = \\bigvee_{\\forall (i,j)}^{m,k}(x_i\\land \\lnot y_j) = \\left(\\bigvee_{i=1}^{m} x_i\\right) \\land \\left(\\bigvee_{i=1}^{k} \\lnot y_i\\right)\\] Next, we introduce the threshold functions which can be classified as pseudo-Boolean: exp_act_win: \\[f_{act-win}(x,y)=\\begin{cases} 1, &amp; \\text{for } \\sum_{i=1}^{m} x_i \\ge \\sum_{i=1}^{k} y_i\\\\ 0, &amp; \\text{otherwise} \\end{cases}\\] exp_inh_win: \\[f_{inh-win}(x,y)=\\begin{cases} 1, &amp; \\text{for } \\sum_{i=1}^{m} x_i \\gt \\sum_{i=1}^{k} y_i\\\\ 0, &amp; \\text{otherwise} \\end{cases}\\] Note that: \\(f_{inh-win}(x,y) = \\lnot f_{act-win}(y,x)\\). These functions are still categorized as BBRs, since they balance the additive activity of the activators and the inhibitors. I searched for an analytical formula for the two last functions (they get pretty big!). More info and discussion about these 2 last formulas, see the math.stackexchange question. Truth Density Data Analysis Data Truth Density (TD) of a boolean equation/expression, given it’s equivalent truth table, is the number of rows that the expression is active divided to the total number of rows \\((2^n)\\). I created every possible truth table for up to \\(20\\) variables (variables here means regulators for us) and calculated the AND-NOT, OR-NOT, BalanceOp1, exp_act_win, exp_inh_win results for every possible configuration of the number of activators and inhibitors that added up to the number of regulators. Then, from the truth tables I calculated the truth density of each operator in each particular configuration. See part of the data below: stats = readRDS(file = &quot;data/td_stats.rds&quot;) DT::datatable(data = stats, caption = htmltools::tags$caption(&quot;Truth Density Data&quot;, style=&quot;color:#dd4814; font-size: 18px&quot;), options = list(pageLength = 6, scrollX = TRUE, order = list(list(1, &quot;asc&quot;)))) %&gt;% formatRound(4:8, digits = 2) Use the get_stats.R script to reproduce this data. Truth Density formulas Also, I have proved the exact formulas for the truth densities in the case of the AND-NOT and OR-NOT link operators (see here for a proof sketch). I write them here explicitly, as well as their long-term behaviour (for large \\(n\\). number of regulators): AND-NOT: \\[TD_{AND-NOT}=\\frac{2^m-1}{2^n} \\xrightarrow{n \\text{ large}} \\frac{1}{2^k}\\] OR-NOT: \\[TD_{OR-NOT}=\\frac{2^n-2^k}{2^n} \\xrightarrow{n \\text{ large}} 1-\\frac{1}{2^m}\\] For large \\(n\\), the \\(TD_{AND-NOT}\\) depends only on the number of inhibitors while the \\(TD_{OR-NOT}\\) depends only on the number of activators. Also, again for large \\(n\\), the extreme case of having a TD value equal to \\(0.5\\) is a result of having only one of the regulators being an inhibitor (activator) of the AND-NOT (OR-NOT) equation. We can use the data above to validate the formulas from the proof (up to \\(n=20\\)): # Validate AND-NOT Truth Density formula formula_td_and_not = stats %&gt;% mutate(formula_td_and_not = (2^num_act - 1)/(2^num_reg)) %&gt;% pull(formula_td_and_not) all(stats %&gt;% pull(td_and_not) == formula_td_and_not) [1] TRUE # Validate OR-NOT Truth Density formula formula_td_or_not = stats %&gt;% mutate(formula_td_or_not = (((2^num_act - 1) * (2^num_inh)) + 1)/(2^num_reg)) %&gt;% pull(formula_td_or_not) all(stats %&gt;% pull(td_or_not) == formula_td_or_not) [1] TRUE AND-NOT vs OR-NOT TD Comparing the AND-NOT and OR-NOT truth densities across the number of regulators: # tidy up data stats_and_or = pivot_longer(data = stats, cols = c(td_and_not, td_or_not), names_to = &quot;lo&quot;, values_to = &quot;td&quot;) %&gt;% select(num_reg, lo, td) %&gt;% mutate(lo = replace(x = lo, list = lo == &quot;td_and_not&quot;, values = &quot;AND-NOT&quot;)) %&gt;% mutate(lo = replace(x = lo, list = lo == &quot;td_or_not&quot;, values = &quot;OR-NOT&quot;)) %&gt;% rename(`Link Operator` = lo) ggboxplot(data = stats_and_or, x = &quot;num_reg&quot;, y = &quot;td&quot;, color = &quot;Link Operator&quot;, palette = &quot;Set1&quot;, title = &quot;AND-NOT vs OR-NOT Truth Densities&quot;, xlab = &quot;Number of regulators&quot;, ylab = &quot;Truth Density&quot;) + theme(plot.title = element_text(hjust = 0.5)) Figure 1: AND-NOT vs OR-NOT Truth Densities across all possible activators and inhibitors combinations up to 20 regulators The more regulators there are, the more likely it is that the AND-NOT link operator in the boolean equation will result in an inhibited target and that the OR-NOT link operator in an active target. For \\(n&gt;6\\), the points outside the boxplots (with a truth density of \\(\\frac{1}{2}, \\frac{1}{4}, 1-\\frac{1}{4},\\frac{1}{8},1-\\frac{1}{8},...\\)) correspond to the long-term behaviour of the truth density formulas shown above, but where there is also large imbalance between the number of activators and inhibitors. We can also check the relation between TD and number of activators and inhibitors in each case. The following two figures show us why the number of inhibitors are more decisive in the AND-NOT case: ggscatter(data = stats %&gt;% rename(`#Regulators` = num_reg), x = &quot;num_inh&quot;, y = &quot;td_and_not&quot;, color = &quot;#Regulators&quot;, ylab = &quot;Truth Density&quot;, xlab = &quot;Number of Inhibitors&quot;, title = &quot;AND-NOT TD vs Number of Inhibitors&quot;) + theme(plot.title = element_text(hjust = 0.5)) ggscatter(data = stats %&gt;% rename(`#Regulators` = num_reg), x = &quot;num_act&quot;, y = &quot;td_and_not&quot;, color = &quot;#Regulators&quot;, ylab = &quot;Truth Density&quot;, xlab = &quot;Number of Activators&quot;, title = &quot;AND-NOT TD vs Number of Activators&quot;) + theme(plot.title = element_text(hjust = 0.5)) Figure 2: AND-NOT TD vs Number of Activators and Inhibitors In the OR-NOT case the number of activators is more important: ggscatter(data = stats %&gt;% rename(`#Regulators` = num_reg), x = &quot;num_inh&quot;, y = &quot;td_or_not&quot;, color = &quot;#Regulators&quot;, ylab = &quot;Truth Density&quot;, xlab = &quot;Number of Inhibitors&quot;, title = &quot;OR-NOT TD vs Number of Inhibitors&quot;) + theme(plot.title = element_text(hjust = 0.5)) ggscatter(data = stats %&gt;% rename(`#Regulators` = num_reg), x = &quot;num_act&quot;, y = &quot;td_or_not&quot;, color = &quot;#Regulators&quot;, ylab = &quot;Truth Density&quot;, xlab = &quot;Number of Activators&quot;, title = &quot;OR-NOT TD vs Number of Activators&quot;) + theme(plot.title = element_text(hjust = 0.5)) Figure 3: OR-NOT TD vs Number of Activators and Inhibitors BalanceOp1 TD If we add the BalanceOp1 formuls’s TD results to the first plot we have: # tidy up data stats_and_or_balance = pivot_longer(data = stats, cols = c(td_and_not, td_or_not, td_balance_op), names_to = &quot;lo&quot;, values_to = &quot;td&quot;) %&gt;% select(num_reg, lo, td) %&gt;% mutate(lo = replace(x = lo, list = lo == &quot;td_and_not&quot;, values = &quot;AND-NOT&quot;)) %&gt;% mutate(lo = replace(x = lo, list = lo == &quot;td_or_not&quot;, values = &quot;OR-NOT&quot;)) %&gt;% mutate(lo = replace(x = lo, list = lo == &quot;td_balance_op&quot;, values = &quot;BalanceOp1&quot;)) %&gt;% rename(`Link Operator` = lo) ggboxplot(data = stats_and_or_balance, x = &quot;num_reg&quot;, y = &quot;td&quot;, color = &quot;Link Operator&quot;, palette = &quot;Set1&quot;, title = &quot;AND-NOT vs OR-NOT vs BalanceOp1 Truth Densities&quot;, xlab = &quot;Number of regulators&quot;, ylab = &quot;Truth Density&quot;) + theme(plot.title = element_text(hjust = 0.5)) Figure 4: AND-NOT vs OR-NOT vs BalanceOp1 Truth Densities across all possible activators and inhibitors combinations up to 20 regulators The BalanceOp1 TD values are closer to the TD values of the OR-NOT formula compared to the AND-NOT one. The BalanceOp1 is less biased compared to the OR-NOT link operator, but still for large \\(n\\) (regulators) it practically makes the target activated. As we can see in the following two figures, the BalanceOp1 shows a more balanced dependency between the number of activators and inhibitors: ggscatter(data = stats %&gt;% rename(`#Regulators` = num_reg), x = &quot;num_inh&quot;, y = &quot;td_balance_op&quot;, color = &quot;#Regulators&quot;, ylab = &quot;Truth Density&quot;, xlab = &quot;Number of Inhibitors&quot;, title = &quot;BalanceOp1 TD vs Number of Inhibitors&quot;) + theme(plot.title = element_text(hjust = 0.5)) ggscatter(data = stats %&gt;% rename(`#Regulators` = num_reg), x = &quot;num_act&quot;, y = &quot;td_balance_op&quot;, color = &quot;#Regulators&quot;, ylab = &quot;Truth Density&quot;, xlab = &quot;Number of Activators&quot;, title = &quot;BalanceOp1 TD vs Number of Activators&quot;) + theme(plot.title = element_text(hjust = 0.5)) Figure 5: BalanceOp1 TD vs Number of Activators and Inhibitors Threshold Functions TD In contrast, if we check the truth density of the \\(f_{act-win}(x,y)\\) and \\(f_{inh-win}(x,y)\\) boolean functions we have: # tidy up data stats_functions = pivot_longer(data = stats, cols = c(td_exp_act, td_exp_inh), names_to = &quot;fun&quot;, values_to = &quot;td&quot;) %&gt;% select(num_reg, fun, td) %&gt;% mutate(fun = replace(x = fun, list = fun == &quot;td_exp_act&quot;, values = &quot;Activators Win&quot;)) %&gt;% mutate(fun = replace(x = fun, list = fun == &quot;td_exp_inh&quot;, values = &quot;Inhibitors Win&quot;)) %&gt;% rename(`Equation Formula` = fun) ggboxplot(data = stats_functions, x = &quot;num_reg&quot;, y = &quot;td&quot;, color = &quot;Equation Formula&quot;, palette = &quot;lancet&quot;, title = TeX(&quot;Truth Densities of $f_{act-win}(x,y)$ and $f_{inh-win}(x,y)$&quot;), xlab = &quot;Number of regulators&quot;, ylab = &quot;Truth Density&quot;) + theme(plot.title = element_text(hjust = 0.5)) Figure 6: Truth Desities of two robust boolean formulas across all possible activators and inhibitors combinations up to 20 regulators Both boolean functions have a large variance of truth densities irrespective of the number of regulators. The median values seem to converge to \\(0.5\\) for both formulas. The median value of truth density for the \\(f_{act-win}(x,y)\\) is always larger than the \\(f_{inh-win}(x,y)\\) (as expected). TD Data Distance We check how close are the truth density values of the different proposed BBRs, also compared to the proportion of activators, e.g. if a BBR has 1 activator and 5 inhibitors (resp. 5 activators and 1 inhibitor) I would expect my regulatory function’s output to be statistically more inhibited (resp. activated). We find the euclidean distance between the different truth density values and show them in a table and dendrogram format: act_prop = stats %&gt;% mutate(act_prop = num_act/num_reg) %&gt;% pull(act_prop) td_and_not = stats %&gt;% pull(td_and_not) td_or_not = stats %&gt;% pull(td_or_not) td_balance_op = stats %&gt;% pull(td_balance_op) td_exp_act = stats %&gt;% pull(td_exp_act) td_exp_inh = stats %&gt;% pull(td_exp_inh) d = dist(rbind(act_prop, td_and_not, td_or_not, td_balance_op, td_exp_act, td_exp_inh)) # color `act_prop` column breaks = quantile(unname(as.matrix(d)[, &quot;act_prop&quot;]), probs = seq(.05, .95, .05), na.rm = TRUE) col = round(seq(255, 40, length.out = length(breaks) + 1), 0) %&gt;% {paste0(&quot;rgb(255,&quot;, ., &quot;,&quot;, ., &quot;)&quot;)} # red caption.title = &quot;Euclidean Distances between vectors of truth density values (Symmetric)&quot; DT::datatable(data = d %&gt;% as.matrix(), options = list(dom = &quot;t&quot;, scrollX = TRUE), caption = htmltools::tags$caption(caption.title, style=&quot;color:#dd4814; font-size: 18px&quot;)) %&gt;% formatRound(1:6, digits = 3) %&gt;% formatStyle(columns = c(&quot;act_prop&quot;), backgroundColor = styleInterval(breaks, col)) plot(hclust(dist(d)), main = &quot;Distance Dendogram of Thruth Densities&quot;, ylab = &quot;Euclidean Distance&quot;, sub = &quot;BBR Truth Densities&quot;, xlab = &quot;&quot;) The threshold functions have truth densities values that are closer to the proportion of activators for a varying number of regulators, compared to the AND-NOT and OR-NOT formulas. As such they represent more realistic candidates for regulatory functions from a statistical point of view. The TD values of OR-NOT and BalanceOp1 are in general very close (as we’ve also seen in previous Figure) Correlation We will now check the correlation between each pair of operators/proposed functions, as well as the number of regulators, inhibitors and activators: M = cor(stats, method = &quot;kendall&quot;) res = cor.mtest(stats, method = &quot;kendall&quot;) corrplot(corr = M, type = &quot;upper&quot;, p.mat = res$p, sig.level = c(.001, .01, .05), pch.cex = 1, pch.col = &quot;white&quot;, insig = &quot;label_sig&quot;, tl.col = &quot;black&quot;, tl.srt = 45) Figure 7: Correlation Matrix of Truth Densities and number of regulators The two functions results \\(f_{act-win}(x,y), f_{inh-win}(x,y)\\) are highly correlated as expected Lower AND-NOT TD values highly correlate with higher number of inhibitors Higher OR-NOT TD values highly correlate with higher number of activators "],
["cascade-1-0-analysis-all-models.html", "CASCADE 1.0 Analysis (All models) Network Properties Model Stable State Statistics Stable States Data Parameterization vs #fixpoints", " CASCADE 1.0 Analysis (All models) Network Properties In this section we demonstrate the scale-free properties of the CASCADE 1.0 network. We show that both in- and out-degree distributions are asymptotically power-law. Use the script get_distribution_stats.R to generate the degree distribution stats. We load the results: dd_stats = readRDS(file = &quot;data/dd_stats.rds&quot;) dd_stats %&gt;% group_by(in_degree) %&gt;% tally() %&gt;% ggplot(aes(x = in_degree, y = n)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;steelblue&quot;, width = 0.7) + geom_smooth(aes(color = &quot;red&quot;), se = FALSE, show.legend = FALSE) + theme_classic() + labs(title = &quot;In-Degree Distribution (CASCADE 1.0)&quot;, x = &quot;In Degree&quot;, y = &quot;Number of Nodes&quot;) Figure 8: In Degree Distribution (CASCADE 1.0) dd_stats %&gt;% group_by(out_degree) %&gt;% tally() %&gt;% ggplot(aes(x = out_degree, y = n)) + geom_bar(stat = &quot;identity&quot;, fill = &quot;steelblue&quot;) + geom_smooth(aes(color = &quot;red&quot;), se = FALSE, span = 0.58, show.legend = FALSE) + theme_classic() + labs(title = &quot;Out-Degree Distribution (CASCADE 1.0)&quot;, x = &quot;Out Degree&quot;, y = &quot;Number of Nodes&quot;) Figure 9: Out Degree Distribution (CASCADE 1.0) Model Stable State Statistics Using abmlog we generated all \\(2^{23} = 8388608\\) possible link operator mutated models for the CASCADE 1.0 topology. The models are stored in both .gitsbe and .bnet files in the Zenodo dataset . The gitsbe files include also the fixpoint attractors. Thus we can find the frequency distribution of the number of fixpoints across all produced models (use the script count_model_ss.R). The model stable state (fixpoint) statistics are as follows: models_ss_stats = readRDS(file = &quot;data/models_ss_stats.rds&quot;) models_ss_stats %&gt;% group_by(ss_num) %&gt;% tally() %&gt;% ggplot(aes(x = ss_num, y = n, fill = as.factor(ss_num))) + geom_bar(stat = &quot;identity&quot;, show.legend = FALSE) + geom_text(aes(label = n), vjust = -0.5) + geom_text(aes(label = paste0(100 * round(n/nrow(models_ss_stats), digits = 2), &quot;%&quot;)), size = 10, vjust = c(2.5, 2.5, -2)) + theme_classic2() + theme(plot.title = element_text(hjust = 0.5)) + labs(title = &quot;Stable States Distribution&quot;, x = &quot;Number of Stable States&quot;, y = &quot;Number of models&quot;) Figure 10: Stable States Distribution across all link-operator parameterized models (CASCADE 1.0) Less than \\(50\\%\\) of the total possible parameterized models have a single fixpoint attractor which corresponds to a single stable phenotype behaviour. Stable States Data To load the stable state data for the models that have 1 stable state use the Zenodo dataset and the script get_ss_data.R Parameterization vs #fixpoints In this subsection we identidy the key nodes whose parameterization affects the change of dynamics of the CASCADE 1.0 network, i.e. are responsible for the change in the number of fixpoint attractors (0,1 and 2) across all link-operator mutated models. We will use several statistical methods, in each of the sub-sections below. The training data is a link-operator matrix, where rows are models (\\(2^{23}\\)), columns/features/variables are link-operator nodes (\\(23\\) in total) and the parameterization values correspond to \\(0\\) (AND-NOT) or \\(1\\) (OR-NOT). The ternary response for each model is a number denoting the number of fixpoints (\\(0,1\\) or \\(2\\)). The matrix we can generate with the script get_lo_mat.R and the response is part of the previously generated data from the script count_model_ss.R. Glmnet Use the script param_ss_glmnet.R to fit a multinomial LASSO model for the data (Friedman, Hastie, and Tibshirani 2010). We now simply load the result object: fit_a1 = readRDS(file = &quot;data/fit_a1.rds&quot;) plot(fit_a1, xvar = &quot;dev&quot;, type.coef = &quot;2norm&quot;) plot(fit_a1, xvar = &quot;lambda&quot;, type.coef = &quot;2norm&quot;) As we can see there is no \\(\\lambda\\) that could explain more than \\(44\\%\\) of the deviance and there are a lot of non-zero coefficients associated with smaller values of \\(\\lambda\\). For example, choosing \\(\\lambda = 0.0142\\) (tested prediction accuracy \\(\\approx 0.72\\) on a random subset of the data), we have the following coefficients, shown in a heatmap: # choose a lambda lambda1 = fit_a1$lambda[32] fit_a1_coef = coef(fit_a1, s = lambda1) %&gt;% lapply(as.matrix) %&gt;% Reduce(cbind, x = .) %&gt;% t() rownames(fit_a1_coef) = names(coef(fit_a1, s = lambda1)) # 0, 1 and 2 stable states imp_nodes_colors = rep(&quot;black&quot;, length(colnames(fit_a1_coef))) names(imp_nodes_colors) = colnames(fit_a1_coef) imp_nodes_colors[names(imp_nodes_colors) %in% c(&quot;MEK_f&quot;, &quot;PTEN&quot;, &quot;MAPK14&quot;)] = &quot;green4&quot; ComplexHeatmap::Heatmap(matrix = fit_a1_coef, name = &quot;Coef&quot;, row_title = &quot;Number of Fixpoints&quot;, row_names_side = &quot;right&quot;, row_dend_side = &quot;right&quot;, row_title_side = &quot;right&quot;, column_title = &quot;Glmnet Coefficient Scores (λ = 0.0142)&quot;, column_dend_height = unit(20, &quot;mm&quot;), column_names_gp = gpar(col = imp_nodes_colors)) Figure 11: Heatmap of coefficients of multinomial model (glmnet) # check accuracy # lo_mat = readRDS(file = &quot;data/lo_mat.rds&quot;) # models_ss_stats = readRDS(file = &quot;data/models_ss_stats.rds&quot;) # ss_num = models_ss_stats %&gt;% pull(ss_num) # set.seed(42) # model_indexes = sample(x = 1:nrow(lo_mat), size = 100000) # pred = predict(object = fit_a1, newx = lo_mat[model_indexes, ], # type = &quot;class&quot;, s = lambda1) %&gt;% as.integer() # acc = sum(pred == ss_num[model_indexes])/length(pred) # print(acc) # should be ~ 0.72 Even thought the glmnet classifier might not be accurate enough, we still find that the nodes PTEN and MAPK14 are the most important (larger coefficients) for distinguishing between the models with different number of fixpoints. Additional nodes (like MEK_f and CTNNB1) are likely to be importane as well. If we cross-validate the regularization parameter \\(\\lambda\\) (using the same script, we randomly selected smaller model samples - \\(100000\\), \\(20\\) times in total), and choose the \\(\\lambda_{1se}\\) for each different run to get the coefficients, the results can be visualized as follows: cvfit_data = readRDS(file = &quot;data/cvfit_data.rds&quot;) cvfit_mat_list = lapply(cvfit_data, function(cvfit) { co = coef(cvfit) %&gt;% lapply(as.matrix) %&gt;% Reduce(cbind, x = .) %&gt;% t() rownames(co) = names(coef(cvfit)) # 0,1 and 2 stable states return(co) }) cvfit_mat = do.call(rbind, cvfit_mat_list) imp_nodes_colors = rep(&quot;black&quot;, length(colnames(cvfit_mat))) names(imp_nodes_colors) = colnames(cvfit_mat) imp_nodes_colors[names(imp_nodes_colors) %in% c(&quot;MEK_f&quot;, &quot;PTEN&quot;, &quot;MAPK14&quot;, &quot;CTNNB1&quot;, &quot;mTORC1_c&quot;)] = &quot;green4&quot; ComplexHeatmap::Heatmap(matrix = cvfit_mat, name = &quot;Coef&quot;, row_title = &quot;Number of Fixpoints&quot;, row_dend_side = &quot;right&quot;, row_title_side = &quot;left&quot;, column_title = &quot;Glmnet Coefficient Scores&quot;, row_km = 3, row_km_repeats = 10, show_row_names = FALSE, column_dend_height = unit(20, &quot;mm&quot;), column_names_gp = gpar(col = imp_nodes_colors), left_annotation = rowAnnotation(foo = anno_block( labels = c(&quot;2&quot;, &quot;1&quot;, &quot;0&quot;), # with `show_row_names = TRUE` you can check this labels_gp = gpar(col = &quot;black&quot;, fontsize = 12)))) Figure 12: Heatmap of coefficients of multinomial model (glmnet - 20 CV models) The top 5 most important nodes are seen in green in the above heatmap: MAPK14, PTEN, CTNNB1, MEK_f and mTORC1_c. Random Forest We used the param_ss_randf.R script to tune and train a random forest classifier on the dataset (Liaw and Wiener 2002). First we tuned the mtry parameter, the number of variables randomly selected at each tree split: mtry_data = readRDS(file = &quot;data/mtry_data.rds&quot;) mtry_data %&gt;% ggplot(aes(x = mtry, y = OOBError, group = mtry)) + geom_boxplot(fill = &quot;green4&quot;) + labs(title = &quot;Tuning Random Forest mtry parameter&quot;) + theme_classic(base_size = 14) + theme(plot.title = element_text(hjust = 0.5)) Figure 13: Random Forest Tuning (mtry) A value between \\(14-18\\) for mtry seems to minimize the Out-Of-Bag Error, so we choose \\(16\\) for the rest of the analysis. For the number of trees parameter, we stayed with the default value (\\(500\\)) as we observed that they were more than enough after a few test runs. Next, we randomly selected \\(100000\\) models from the dataset - a total of \\(20\\) times - to train the random forest classifier and find the importance score of each node. We load the result data and tidy up a bit: rf_imp_data = readRDS(file = &quot;data/rf_imp_data.rds&quot;) # make a list of tibbles tbl_list = lapply(rf_imp_data, function(mat) { nodes = rownames(mat) tibble::as_tibble(mat) %&gt;% mutate(nodes = nodes) }) # OneForAll imp_res = dplyr::bind_rows(tbl_list) # Get the importance stats imp_stats = imp_res %&gt;% group_by(nodes) %&gt;% summarise(mean_acc = mean(MeanDecreaseAccuracy), sd_acc = sd(MeanDecreaseAccuracy), mean_gini = mean(MeanDecreaseGini), sd_gini = sd(MeanDecreaseGini), .groups = &#39;keep&#39;) %&gt;% ungroup() The importance scores for each node were the mean decrease in accuracy and node impurity (Gini Index). We calculate the mean importance and standard deviation scores across all random samples for both measures of importance: # color first 5 nodes in x axis imp_col = c(rep(&quot;green4&quot;, 5), rep(&quot;grey30&quot;, nrow(imp_stats)-5)) imp_stats %&gt;% mutate(nodes = forcats::fct_reorder(nodes, desc(mean_acc))) %&gt;% ggplot(aes(x = nodes, y = mean_acc, fill = mean_acc)) + geom_bar(stat = &quot;identity&quot;, show.legend = FALSE) + scale_fill_gradient(low = &quot;steelblue&quot;, high = &quot;red&quot;) + geom_errorbar(aes(ymin=mean_acc-sd_acc, ymax=mean_acc+sd_acc), width = 0.2) + theme_classic(base_size = 14) + theme(axis.text.x = element_text(angle = 90, colour = imp_col)) + labs(title = &quot;Random Forest Variable Importance (Accuracy)&quot;, x = &quot;Nodes&quot;, y = &quot;Mean Decrease Accuracy&quot;) Figure 14: Random Forest: Mean Decrease Accuracy per node imp_stats %&gt;% mutate(nodes = forcats::fct_reorder(nodes, desc(mean_gini))) %&gt;% ggplot(aes(x = nodes, y = mean_gini, fill = mean_gini)) + geom_bar(stat = &quot;identity&quot;, show.legend = FALSE) + scale_fill_gradient(low = &quot;steelblue&quot;, high = &quot;red&quot;) + geom_errorbar(aes(ymin = mean_gini-sd_gini, ymax = mean_gini+sd_gini), width = 0.2) + theme_classic(base_size = 14) + theme(axis.text.x = element_text(angle = 90, colour = imp_col)) + labs(title = &quot;Random Forest Variable Importance (Gini Index)&quot;, x = &quot;Nodes&quot;, y = &quot;Mean Decrease in Node Impurity&quot;) Figure 15: Random Forest: Mean Node Impurity (Gini Index) The top 5 important nodes by any of the two importance measures using Random Forests, include the nodes found as important with the LASSO method: MAPK14, ERK_f, MEK_f, PTEN, mTORC1_c. Same results we get when using a faster, more memory efficient and with multi-thread support, random forest R package, namely ranger (Wright and Ziegler 2017). Use the script param_ss_ranger.R to reproduce the results (\\(4000000\\) - almost half of the models are used for training and the importance measure calculated was the Gini index): ranger_res = readRDS(file = &quot;data/ranger_res.rds&quot;) imp_res = tibble(nodes = names(ranger_res$variable.importance), gini_index = ranger_res$variable.importance) imp_res %&gt;% mutate(nodes = forcats::fct_reorder(nodes, desc(gini_index))) %&gt;% ggplot(aes(x = nodes, y = gini_index, fill = gini_index)) + geom_bar(stat = &quot;identity&quot;, show.legend = FALSE) + scale_fill_gradient(low = &quot;steelblue&quot;, high = &quot;red&quot;) + theme_classic(base_size = 14) + theme(axis.text.x = element_text(angle = 90, colour = imp_col)) + labs(title = &quot;Random Forest (Ranger) Variable Importance (Gini Index)&quot;, x = &quot;Nodes&quot;, y = &quot;Mean Decrease in Node Impurity&quot;) Figure 16: Random Forest (ranger): Mean Node Impurity (Gini Index) Parameterization Map We use UMAP (McInnes, Healy, and Melville 2018) to reduce the dimensionality of our dataset from \\(23\\) (number of nodes with link operators) to \\(2\\) and visualize it to see if there is any apparent visual relation between the models parameterization and number of fixpoints. Note that because of memory restrictions (we had a total of 16GB available) we couldn’t run UMAP on the whole dataset. We used the param_ss_umap.R script to run the UMAP implementation offered by the uwot R package. We make the plots afterwards using the result data with the param_ss_umap_vis.R script. Unsupervised UMAP First, we randomly choose a subset of our dataset (\\(6000000\\) rows, so \\(\\approx 71\\%\\) of the link operator models) and applied unsupervised UMAP (no a priori knowledge of the number of fixpoints per model provided or of any other information/label per model for that matter). UMAP is given a subset of all binary numbers from \\(0\\) (\\(23\\) \\(0\\)’s) to \\(2^{23}-1\\) (\\(23\\) \\(1\\)’s) representing each possible link operator mutated model (\\(0\\)’s map to AND-NOT, \\(1\\)’s to OR-NOT) and places them in the 2D plane. The following figure show us the models, colored by their decimal (base-10) number (converted from the binary link-operator model representation): knitr::include_graphics(path = &quot;img/umap_unsupervised_model_num.png&quot;) Figure 17: UMAP: Parameterization vs Numerical Model Representation UMAP has found neighboorhoods of similarly parameterized models. We used the manhattan distance metric in the UMAP algorithm and as such, a model number that can be more than a thousands of numbers away on the decimal system from another model number, might actually be very close to it if we check the corresponding distance of their binary representations (e.g. the manhattan distance between \\(000...00_2=0\\) \\(100...00_2=2^{22}=4194304\\) is 1). Same models, same 2D placement, only now colored by their number of fixpoints: knitr::include_graphics(path = &quot;img/umap_unsupervised.png&quot;) Figure 18: UMAP: Parameterization vs Number of fixpoints Models with similar parameterization seem to also have the same number of fixpoints. We also notice specific subareas being completely covered by such same-structure, same-fixpoint-number models (\\(0\\) or \\(1\\)-fixpoint model clusters) showing us that some parameterization families are eligible to the same attractor fate. The \\(2\\)-fixpoint models seem to always lie next to similarly parameterized \\(1\\)-fixpoint models (they are like a subcategory of those and not like a separate one) and not in clusters of their own. As such, they can be found cross all the areas of the parameterization map. Supervised UMAP Next, we randomly choose \\(1/3=33\\%\\) of our dataset and applied UMAP in supervised mode (the association between each model and the corresponding fixpoint group was given as input to UMAP): knitr::include_graphics(path = &quot;img/umap_supervised.png&quot;) Figure 19: UMAP Supervised: Parameterization vs Number of fixpoints We observe that the \\(2\\)-fixpoint model structures are spread out in the Y dimension much less than the corresponding \\(0\\) and \\(1\\)-fixpoint models. So, it seems that the more complex are the models (here we mean dynamical complexity - i.e. more attractors) the more spread out are in the parameterization map and form many more distinct clusters. If we retain the above fixpoint-class 2D model placement and color it according to the models numerical representation, we can see the existence of small closely-parameterized clusters within each super-cluster as well as the fact that the models in each super-cluster are spread throughout the parameterization landscape: knitr::include_graphics(path = &quot;img/umap_supervised_model_num.png&quot;) Figure 20: UMAP Supervised: Parameterization vs Numerical Model Representation Embedding Important Nodes in the Map Using random forest and regularized LASSO method, we found important nodes whose parameterization affects the change of dynamics (number of fixpoints). Using (supervised) UMAP we took a sample of the dataset (\\(33\\%\\) of the models) and placed it to the 2D plane, linking closely parameterized models in clusters. We will now color the supervised UMAP-generated map with the link-operator values of the top 5 most important nodes found from the aforementioned methods as well the least important node reported with random forests (use the param_ss_umap_sup_imp_nodes.R script). The 3 most important nodes: knitr::include_graphics(path = &quot;img/umap_supervised_MAPK14.png&quot;) knitr::include_graphics(path = &quot;img/umap_supervised_MEK_f.png&quot;) knitr::include_graphics(path = &quot;img/umap_supervised_ERK_f.png&quot;) The next 2 most important nodes: knitr::include_graphics(path = &quot;img/umap_supervised_mTORC1_c.png&quot;) knitr::include_graphics(path = &quot;img/umap_supervised_PTEN.png&quot;) CFLAR was the least important node for assessing the number of fixpoints of a model from its parameterization: knitr::include_graphics(path = &quot;img/umap_supervised_CFLAR.png&quot;) We can see a visual link between node importance (related to #fixpoints) and link operator assignment: the less important a node is, the more randomly distributed it’s link-operator values are across the parameterization map. The important nodes can be used to more accurately define families of closely parameterized models. "],
["cascade-1-0-analysis-1-ss-models.html", "CASCADE 1.0 Analysis (1 ss models) Parameterization and Stable State Agreement Parameterization and Stable State Agreement (Cascade 2.0) 2D Model Parameterization Maps Gitsbe Models on the Map Performance Maps Performance biomarkers Fitness Maps Performance vs Fitness Synergy Maps Synergy Biomarkers", " CASCADE 1.0 Analysis (1 ss models) In the second part of this analysis, only the models that have 1 stable state will be used (see Stable States Data). All variables of interest (stable state, link-operator parameterization, fitness to steady state, performance MCC score, etc.) will relate only to the 1 stable state models from now on. Parameterization and Stable State Agreement We calculate the node_stats tibble object using the get_node_stats.R script. This object includes the agreement statistics information for each node that has a link operator (i.e. it is targeted by both activators and inhibitors). Load the node_stats: node_stats = readRDS(file = &quot;data/node_stats.rds&quot;) We are interested in two variables of interest: Parameterization of a link operator node: AND-NOT (0) vs OR-NOT (1) Stable State of a node: inhibited (0) vs active (1) There exist are 4 different possibilities related to 2 cases: 0-0, 1-1 =&gt; parameterization and stable state match (e.g. node was parameterized with AND-NOT and it’s state was inhibited or it had OR-NOT and its state was active) 1-0, 0-1 =&gt; parameterization and stable state differ (e.g. node had OR-NOT and its state was inhibited, or AND-NOT and it’s state was active) In the next Figure we show the total observed proportionate agreement for each node, which is the number of models for which parameterization and stable state matched (case 1 above) divided by the total amount of models: node_stats %&gt;% mutate(node = forcats::fct_reorder(node, desc(num_reg))) %&gt;% ggplot(aes(x = node, y = obs_prop_agreement, fill = as.factor(num_reg))) + geom_bar(stat = &quot;identity&quot;) + scale_y_continuous(labels=scales::percent) + labs(title = &quot;Agreement between Link Operator Parameterization and Stable State Activity&quot;, x = &quot;Target Nodes with both activating and inhibiting regulators&quot;, y = &quot;Observed Proportionate Agreement&quot;) + theme_classic() + theme(axis.text.x = element_text(angle = 90)) + scale_fill_brewer(guide = guide_legend(reverse=TRUE, title = &quot;#Regulators&quot;), palette = &quot;Set1&quot;) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;) Figure 21: Parameterization and Stable State activity agreement The total barplot area covered (i.e. the total agreement score so to speak) is 77.7294779%. The above score means that the is a higher probability than chance to assign a node the AND-NOT (resp. OR-NOT) link operator in its respective boolean equation and that node at the same time having an inhibited (resp. activated) stable state of 0 (.resp 1) in any CASCADE 1.0 link operator parameterized model. This suggests that the corresponding boolean formula used is biased and the previous analysis in this report showed that for larger networks this behaviour will become statistically more prevalent. As such, even though the number of regulators are less than 6, we find that there is strong agreement between link operator and stable state activity across all the nodes that have both types of regulators (activators and inhibitors). This agreement is stronger for some nodes than others. Next, we calculate per node, the proportion of link operator assignments that retained their expected (i.e. keeping the same digit) stable state activity (e.g. the proportion of models corresponding to the cases 0-0/(0-0 + 0-1) for the AND-NOT link operator - similar for OR-NOT): node_stats %&gt;% mutate(and_not_0ss_prop = and_not_0ss_agreement/(and_not_0ss_agreement + and_not_1ss_disagreement)) %&gt;% mutate(or_not_1ss_prop = or_not_1ss_agreement/(or_not_1ss_agreement + or_not_0ss_disagreement)) %&gt;% select(node, num_reg, and_not_0ss_prop, or_not_1ss_prop, active_prop) %&gt;% rename(`AND-NOT` = and_not_0ss_prop, `OR-NOT` = or_not_1ss_prop) %&gt;% mutate(node = forcats::fct_reorder(node, desc(num_reg))) %&gt;% pivot_longer(cols = c(`AND-NOT`, `OR-NOT`)) %&gt;% ggplot(aes(x = node, y = value, fill = name)) + geom_bar(position = &quot;dodge&quot;, stat = &quot;identity&quot;) + scale_y_continuous(labels=scales::percent) + labs(title = &quot;Link Operator Parameterization Agreement with Stable State Activity&quot;, x = &quot;Target Nodes with both activating and inhibiting regulators&quot;, y = &quot;Observed Proportionate Agreement&quot;) + theme_classic() + theme(axis.text.x = element_text(angle = 90)) + scale_fill_brewer(guide = guide_legend(title = &quot;Link Operator&quot;), palette = &quot;Set1&quot;) + geom_line(aes(y = active_prop, color = active_prop), group = 1, size = 1.2) + scale_color_gradient(labels=scales::percent, low=&quot;grey&quot;, high=&quot;green&quot;, name = &quot;%Models:active node&quot;, limits = c(0,1)) + theme(legend.title = element_text(size = 10)) Figure 22: Parameterization and Stable State activity agreement 2 Higher proportional activity for a node correlates with higher OR-NOT-activated state agreement. LRP_f has 4 activators and 1 inhibitor and from the previous statistical analysis with found that \\(TD_{AND-NOT,4+1}=0.469\\), \\(TD_{OR-NOT,4+1}=0.969\\), numbers which correspond really well with the proportionate agreement scores found across all the CASCADE 1.0 models. TSC_f has 1 activator and 4 inhibitors (which corresponds well to it’s total inhibition profile in all the models). TSC_f and mTORC2_c are always found inhibited and thus the agreement with the AND-NOT-inhibited state is perfect and the OR-NOT-activated state agreement zero. In the above Figure, wherever there is less than 0.5 disagreement, we can always explain it with the activity proportion value and the number of activators being more (or less resp.) than the number of inhibitors - see following table: caption.title = &quot;Link Operator Statistics&quot; DT::datatable(data = node_stats %&gt;% select(node, num_reg, num_act, num_inh), caption = htmltools::tags$caption(caption.title, style=&quot;color:#dd4814; font-size: 18px&quot;), options = list(order = list(list(2, &quot;desc&quot;)))) %&gt;% formatRound(5:6, digits = 3) Parameterization and Stable State Agreement (Cascade 2.0) We will perform the same analysis as in the previous section, only now for a randomly selected sample of models from CASCADE 2.0. CASCADE 2.0 represents a larger topology/network and as such we expect to see even more agreement between stable state activity and link operator assignment (which leads us to link operator bias). The dataset used was generated for another analysis and we are going to use part of it, i.e. the models that had 1 stable state (see get_node_stats_cascade_2.R script). The dataset is stored in Zenodo Load the CASCADE 2.0 node_stats: node_stats = readRDS(file = &quot;data/node_stats_cascade2.rds&quot;) The next Figure shows the total observed proportionate agreement for each link operator node in CASCADE 2.0 (a total of \\(52\\) nodes), which is the number of models for which parameterization and stable state matched divided by the total amount of models (\\(20672\\)): node_stats %&gt;% mutate(node = forcats::fct_reorder(node, desc(num_reg))) %&gt;% ggplot(aes(x = node, y = obs_prop_agreement, fill = as.factor(num_reg))) + geom_bar(stat = &quot;identity&quot;) + scale_y_continuous(labels=scales::percent) + labs(title = &quot;Agreement between Link Operator Parameterization and Stable State Activity&quot;, x = &quot;Target Nodes with both activating and inhibiting regulators&quot;, y = &quot;Observed Proportionate Agreement&quot;) + theme_classic() + theme(axis.text.x = element_text(angle = 90)) + scale_fill_brewer(guide = guide_legend(reverse=TRUE, title = &quot;#Regulators&quot;), palette = &quot;Spectral&quot;) + geom_hline(yintercept = 0.5, linetype = &#39;dashed&#39;) Figure 23: Parameterization and Stable State activity agreement (CASCADE 2.0) The total barplot area covered (i.e. the total agreement score so to speak) is 78.6334916%. The nodes with number of regulators \\(&gt;5\\) have always an observed agreement \\(\\geq 70\\%\\) between stable state activity and link operator parameterization. The above results provide evidence that the statistics-based conclusion we reached in a previous section is correct, i.e. that the standardized boolean formula is biased for larger number of regulators. 2D Model Parameterization Maps In this section we present the results of using UMAP (McInnes, Healy, and Melville 2018) on the link-operator parameterization data of the CASCADE 1.0 models with 1 stable state. We created several such parameterization maps by adjusting the n_neighbors parameter input (from \\(2\\) to \\(20\\)), which is responsible for the size of the local neighborhood (in terms of number of neighboring sample points) used for the manifold approximation. As the documentation says, larger values result in more global views of the manifold, while smaller values result in more local data being preserved. To get these map images and the reduced dimensionality dataset, use the script 1ss_models_umap.R for more details. Note that in all these mappings to the 2D space, models that share similar link-operator parameterization will reside in the same area/cluster in the map. The larger the n_neighbors is, the more the smaller clusters merge into larger ones. The images for \\(\\ge 14\\) n_neighbors are almost exactly the same. We present some of these maps below: knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_2.png&quot;) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_3.png&quot;) Figure 24: 2D Parameterization map for 1 stable state models (2 and 3 neighbours) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_4.png&quot;) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_5.png&quot;) Figure 25: 2D Parameterization map for 1 stable state models (4 and 5 neighbours) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_6.png&quot;) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_8.png&quot;) Figure 26: 2D Parameterization map for 1 stable state models (6 and 8 neighbours) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_9.png&quot;) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_11.png&quot;) Figure 27: 2D Parameterization map for 1 stable state models (9 and 11 neighbours) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_12.png&quot;) knitr::include_graphics(path = &quot;img/1ss_umap/1ss_umap_unsup_15.png&quot;) Figure 28: 2D Parameterization map for 1 stable state models (12 and 15 neighbours) We observe the existence of two large families (superclusters) of parameterization models, especially for more global views of the dataset (\\(\\text{n_neighbors}\\ge 8\\). Gitsbe Models on the Map Gitsbe uses a genetic algorithm approach to produce boolean models that are fitted to basal, biomarker training data. We used Gitsbe and tested the produced models performance (ensemble-wise drug combination predictions) against synergy data from (Flobak et al. 2015) in another report. The calibrated models performed very well in terms of both ROC and PR-AUC. Here we want to check whether models produced by a method such as a genetic algorithm-based one have similar parameterization - i.e. they belong in the same neighbourhood in the parameterization map. We will use models from \\(1000\\) gitsbe simulations, calibrated to steady state (a total of \\(3000\\) models, choosing the best-fit models from each simulation). The results are provided in this data file and to reproduce them, follow the instructions here, keeping the default configuration options for CASCADE 1.0 and changing only the number of simulations to \\(1000\\)). All the Gitsbe models had a large fitness to the steady state AGS data (their stable states fitting almost exactly the states of the manually-curated 24 nodes), as it can be seen from the next figure (see gitsbe_models_fit.R): knitr::include_graphics(path = &quot;img/gitsbe_fit_density.png&quot;) Figure 29: Gitsbe model fitness to AGS steady state To generate the next figures (same map, same gitsbe models, different number of neighbours) use the gitsbe_model_embedding.R: knitr::include_graphics(path = &quot;img/gitsbe_umaps/2nn.png&quot;) knitr::include_graphics(path = &quot;img/gitsbe_umaps/4nn.png&quot;) Figure 30: Gitsbe models in Parameterization map (2 and 4 neighbours) knitr::include_graphics(path = &quot;img/gitsbe_umaps/6nn.png&quot;) knitr::include_graphics(path = &quot;img/gitsbe_umaps/8nn.png&quot;) Figure 31: Gitsbe models in Parameterization map (6 and 8 neighbours) knitr::include_graphics(path = &quot;img/gitsbe_umaps/11nn.png&quot;) knitr::include_graphics(path = &quot;img/gitsbe_umaps/14nn.png&quot;) Figure 32: Gitsbe models in Parameterization map (11 and 14 neighbours) Gitsbe-generated models that fit the basal biomarker steady state data for the AGS cell line have a diverse structure that spans across the parameterization map but nonetheless appear to gather in smaller parameterization-specific sub-clusters (better seen in the Figure with 14 neighbours which gives a more global view of the dataset). Observing the distribution of the gitsbe models in the parameterization map, we see that most of them are being placed at one of the two superclusters. Of course, there are areas in the map that Gitsbe models do not cover, which may as well be high-performance model areas. Since we have generated all possible link-operator models with CASCADE 1.0, we can proceed to generate a performance map atop the parameterization one and cross-check if the gitsbe models fall into high-performance areas or not. Performance Maps Every model generated via abmlog (Model Stable State Statistics) was tested against the synergy dataset of (Flobak et al. 2015). Among \\(21\\) drug combinations, \\(4\\) were found synergistic in that dataset, namely: obs_syn = emba::get_observed_synergies(file = &quot;data/observed_synergies_cascade_1.0&quot;) usefun::pretty_print_vector_values(obs_syn, vector.values.str = &quot;synergies&quot;) 4 synergies: PI-PD, PI-5Z, PD-AK, AK-5Z Using the drabme software module, we tested every CASCADE 1.0 model against this dataset and got each model’s predictions for each drug combination. The HSA rule was used to define if a model is synergistic for a particular combination. The results are available in the Zenodo dataset , file cascade_1.0_hsa_fixpoints.tar.gz. As previously said, we are going to use the 1 stable state model predictions only. We used the emba R package to perform a biomarker analysis on the 1 stable state models dataset and their predictions from drabme (see script emba_analysis.R). Part of the results from the emba analysis is the calculation of the Matthews correlation coefficient (MCC) performance score for each model. We use these MCC model scores to draw the next figures (see mcc_figures.R script) Splitting all the 1 stable state models to \\(4\\) MCC classes we can see that a lot of models have performance close to random prediction or even worse: knitr::include_graphics(path = &quot;img/mcc_hist.png&quot;) Figure 33: MCC Classes Histogram Most of the 1 stable state models have MCC performance close to random or worse, making it thus difficult for any algorithm to find the best performance models (i.e. the 4th MCC class models). If we draw the parameterization maps for different number of neighbours and color the points/models according to their MCC score, we get these images: knitr::include_graphics(path = &quot;img/mcc_maps/2nn.png&quot;) knitr::include_graphics(path = &quot;img/mcc_maps/4nn.png&quot;) Figure 34: MCC Parameterization map (2 and 4 neighbours) knitr::include_graphics(path = &quot;img/mcc_maps/6nn.png&quot;) knitr::include_graphics(path = &quot;img/mcc_maps/8nn.png&quot;) Figure 35: MCC Parameterization map (6 and 8 neighbours) knitr::include_graphics(path = &quot;img/mcc_maps/11nn.png&quot;) knitr::include_graphics(path = &quot;img/mcc_maps/14nn.png&quot;) Figure 36: MCC Parameterization map (11 and 14 neighbours) We observe that the two large parameterization superclusters (especially outlined by the figures with \\(2\\) and \\(\\ge 8\\) neighbours) are closely related with the MCC performance metric. Specifically, these 2 superclusters dichotomize the models performance landscape into 2 areas, where only one of them has the majority of good performance models (i.e. those that have an MCC score \\(&gt;0\\)). This also points us to the existence of link operator biomarkers - nodes whose link operator define the performance of the models, i.e. in which supercluster they belong in the simple dichotomous case scenario where we want to distinguish ‘good’ from ‘bad’ models. Comparing the corresponding Gitsbe parameterization maps with the MCC maps, we can clearly verify now that the Gitsbe models might not always be the best performing ones (in terms of MCC score) since they appear in both superclusters (and that’s only a first-fine measure for performance based on structure), but at least they tend to be more in the higher performance supercluster. This is evidence that suggests that either the genetic algorithm produces local optima (which is known since it’s a heuristic method) or the training dataset does not provide enough constraints, i.e. more nodes whose steady state needs to be fit (or a combination of both). Performance biomarkers The complex heatmap of emba mcc results ranger results, important variables Fitness Maps Performance vs Fitness Synergy Maps Synergy Biomarkers "],
["r-session-info.html", "R session info", " R session info xfun::session_info() R version 3.6.3 (2020-02-29) Platform: x86_64-pc-linux-gnu (64-bit) Running under: Ubuntu 18.04.5 LTS Locale: LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C Package version: abind_1.4-5 assertthat_0.2.1 backports_1.1.9 base64enc_0.1.3 BH_1.72.0.3 bibtex_0.4.2.2 bookdown_0.20 boot_1.3.25 broom_0.7.0 callr_3.4.4 car_3.0-9 carData_3.0-4 cellranger_1.1.0 circlize_0.4.10 Ckmeans.1d.dp_4.3.3 cli_2.0.2 clipr_0.7.0 clue_0.3-57 cluster_2.1.0 codetools_0.2-16 colorspace_1.4-1 compiler_3.6.3 ComplexHeatmap_2.4.2 conquer_1.0.2 corrplot_0.84 cowplot_1.1.0 cpp11_0.2.1 crayon_1.3.4 crosstalk_1.1.0.1 curl_4.3 data.table_1.13.0 desc_1.2.0 digest_0.6.25 dplyr_1.0.2 dqrng_0.2.1 DT_0.15 ellipsis_0.3.1 emba_0.1.7 evaluate_0.14 fansi_0.4.1 farver_2.0.3 FNN_1.1.3 forcats_0.5.0 foreach_1.5.0 foreign_0.8-75 gbRd_0.4-11 generics_0.0.2 GetoptLong_1.0.2 ggplot2_3.3.2 ggpubr_0.4.0 ggrepel_0.8.2 ggsci_2.9 ggsignif_0.6.0 glmnet_4.0-2 GlobalOptions_0.1.2 glue_1.4.2 graphics_3.6.3 grDevices_3.6.3 grid_3.6.3 gridExtra_2.3 gtable_0.3.0 gtools_3.8.2 haven_2.3.1 highr_0.8 hms_0.5.3 htmltools_0.5.0 htmlwidgets_1.5.1 igraph_1.2.5 irlba_2.3.3 isoband_0.2.2 iterators_1.0.12 jsonlite_1.7.1 knitr_1.29 labeling_0.3 later_1.1.0.1 latex2exp_0.4.0 lattice_0.20-41 lazyeval_0.2.2 lifecycle_0.2.0 lme4_1.1.23 magrittr_1.5 maptools_1.0.2 markdown_1.1 MASS_7.3.53 Matrix_1.2-18 MatrixModels_0.4.1 matrixStats_0.56.0 methods_3.6.3 mgcv_1.8.33 mime_0.9 minqa_1.2.4 munsell_0.5.0 nlme_3.1.149 nloptr_1.2.2.2 nnet_7.3.14 openxlsx_4.1.5 parallel_3.6.3 pbkrtest_0.4.8.6 pillar_1.4.6 pkgbuild_1.1.0 pkgconfig_2.0.3 pkgload_1.1.0 png_0.1-7 polynom_1.4.0 praise_1.0.0 prettyunits_1.1.1 processx_3.4.4 progress_1.2.2 promises_1.1.1 ps_1.3.4 purrr_0.3.4 quantreg_5.67 R6_2.4.1 randomForest_4.6-14 ranger_0.12.1 RColorBrewer_1.1-2 Rcpp_1.0.5 RcppAnnoy_0.0.16 RcppArmadillo_0.9.900.3.0 RcppEigen_0.3.3.7.0 RcppProgress_0.4.2 Rdpack_1.0.0 readr_1.3.1 readxl_1.3.1 rematch_1.0.1 rio_0.5.16 rje_1.10.16 rjson_0.2.20 rlang_0.4.7 rmarkdown_2.3 rprojroot_1.3.2 RSpectra_0.16.0 rstatix_0.6.0 rstudioapi_0.11 scales_1.1.1 shape_1.4.5 sitmo_2.0.1 sp_1.4.2 SparseM_1.78 splines_3.6.3 statmod_1.4.34 stats_3.6.3 stringi_1.5.3 stringr_1.4.0 survival_3.2-3 testthat_2.3.2 tibble_3.0.3 tidyr_1.1.2 tidyselect_1.1.0 tinytex_0.25 tools_3.6.3 usefun_0.4.8 utf8_1.1.4 utils_3.6.3 uwot_0.1.8 vctrs_0.3.4 viridisLite_0.3.0 visNetwork_2.0.9 withr_2.2.0 xfun_0.17 yaml_2.2.1 zip_2.1.1 "],
["references.html", "References", " References Flobak, Åsmund, Anaïs Baudot, Elisabeth Remy, Liv Thommesen, Denis Thieffry, Martin Kuiper, and Astrid Lægreid. 2015. “Discovery of Drug Synergies in Gastric Cancer Cells Predicted by Logical Modeling.” Edited by Ioannis Xenarios. PLOS Computational Biology 11 (8): e1004426. https://doi.org/10.1371/journal.pcbi.1004426. Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2010. “Regularization Paths for Generalized Linear Models via Coordinate Descent.” Journal of Statistical Software 33 (1): 1–22. http://www.jstatsoft.org/v33/i01/. Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” R News 2 (3): 18–22. https://cran.r-project.org/doc/Rnews/. McInnes, Leland, John Healy, and James Melville. 2018. “UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction,” February. http://arxiv.org/abs/1802.03426. Mendoza, Luis, and Ioannis Xenarios. 2006. “A method for the generation of standardized qualitative dynamical systems of regulatory networks.” Theoretical Biology and Medical Modelling 3 (1): 13. https://doi.org/10.1186/1742-4682-3-13. Wright, Marvin, and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” Journal of Statistical Software, Articles 77 (1): 1–17. https://doi.org/10.18637/jss.v077.i01. "]
]
